{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hX0JGZUhSzX",
    "outputId": "5bfcb12f-e9d7-4c8c-cf36-636c3422ef2a"
   },
   "outputs": [],
   "source": [
    "#dataset\n",
    "!git clone https://github.com/zzzDavid/ICDAR-2019-SROIE.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDL7O-XJyRZj"
   },
   "source": [
    "## Preprocess Dataset\n",
    "\n",
    "We will preprocess Dataset as per PICK-pytorch.<br>\n",
    "Reference: https://github.com/wenwenyu/PICK-pytorch/blob/master/data/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Djo5um54U80p"
   },
   "outputs": [],
   "source": [
    "## Creating folders for preprocessed dataset\n",
    "!mkdir boxes_and_transcripts images entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAyRCtfx62yA",
    "outputId": "bdd627c2-076d-4bc7-9939-67066fafa65b"
   },
   "outputs": [],
   "source": [
    "## Script for preprocessing dataset\n",
    "import os\n",
    "import pandas\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "## Input dataset\n",
    "data_path = \"ICDAR-2019-SROIE/data/\"\n",
    "box_path = data_path + \"box/\"\n",
    "img_path = data_path + \"img/\"\n",
    "key_path = data_path + \"key/\"\n",
    "\n",
    "## Output dataset\n",
    "out_boxes_and_transcripts = \"boxes_and_transcripts/\"\n",
    "out_images = \"images/\"\n",
    "out_entities  = \"entities/\"\n",
    "\n",
    "train_samples_list =  []\n",
    "for file in os.listdir(data_path + \"box/\"):\n",
    "  \n",
    "  ## Reading csv\n",
    "  with open(box_path +file, \"r\") as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\")\n",
    "    ## arranging dataframe index ,coordinates x1_1,y1_1,x2_1,y2_1,x3_1,y3_1,x4_1,y4_1, transcript\n",
    "    rows = [[1] + x[:8] + [','.join(x[8:]).strip(',')] for x in reader] \n",
    "    df = pandas.DataFrame(rows)\n",
    "  \n",
    "  ## including ner label dataframe index ,coordinates x1_1,y1_1,x2_1,y2_1,x3_1,y3_1,x4_1,y4_1, transcript , ner tag\n",
    "  df[10] = 'other'  \n",
    "  \n",
    "  ##saving file into new dataset folder\n",
    "  jpg = file.replace(\".csv\",\".jpg\")\n",
    "  entities = json.load(open(key_path+file.replace(\".csv\",\".json\")))\n",
    "  for key,value in sorted(entities.items()):\n",
    "    idx = df[df[9].str.contains('|'.join(map(str.strip, value.split(','))))].index\n",
    "    df.loc[idx, 10] = key\n",
    "\n",
    "  shutil.copy(img_path +jpg, out_images)\n",
    "  with open(out_entities + file.replace(\".csv\",\".txt\"),\"w\") as j:  \n",
    "    print(json.dumps(entities), file=j)\n",
    "  \n",
    "  df.to_csv(out_boxes_and_transcripts+file.replace(\".csv\",\".tsv\"),index=False,header=False, quotechar='',escapechar='\\\\',quoting=csv.QUOTE_NONE, )\n",
    "  train_samples_list.append(['receipt',file.replace('.csv','')])\n",
    "train_samples_list = pandas.DataFrame(train_samples_list)\n",
    "train_samples_list.to_csv(\"train_samples_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tilkkORpzkh0",
    "outputId": "2fea7d7c-5136-4328-b94f-454c5c614cd0"
   },
   "outputs": [],
   "source": [
    "## document_type, file_name\n",
    "train_samples_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKfcyJVB3VG5"
   },
   "source": [
    "**Spliting dataset into train-test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAZ6MX9RWH8b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_test = pandas.read_csv(\"train_samples_list.csv\",dtype=str)\n",
    "train, test= train_test_split(train_test,test_size=0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GMj9JCN4Uo2",
    "outputId": "31368e62-e395-4ee8-faa0-daca4b552e3d"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/wenwenyu/PICK-pytorch.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zC4N75ed49Dt"
   },
   "source": [
    "**Copy train data into PICK-pytorch data folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ulyS4bIfIHi"
   },
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "  shutil.copy(out_boxes_and_transcripts+str(row[2])+\".tsv\",'PICK-pytorch/data/data_examples_root/boxes_and_transcripts/')\n",
    "  shutil.copy(out_images+str(row[2])+\".jpg\",'PICK-pytorch/data/data_examples_root/images/')\n",
    "  shutil.copy(out_entities +str(row[2])+\".txt\", 'PICK-pytorch/data/data_examples_root/entities/')\n",
    "\n",
    "train.drop(['Unnamed: 0'], axis = 1,inplace = True)\n",
    "train.reset_index(inplace= True)\n",
    "train.drop(['index'], axis = 1,inplace = True)\n",
    "train.to_csv(\"PICK-pytorch/data/data_examples_root/train_samples_list.csv\",header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJCVKZ1I5FYN"
   },
   "source": [
    "**Copy test data into PICK-pytorch data folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIuRK2bk5TmE"
   },
   "outputs": [],
   "source": [
    "!mkdir 'PICK-pytorch/data/test_data_example/entities/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "  shutil.copy(out_boxes_and_transcripts+str(row[2])+\".tsv\",'PICK-pytorch/data/test_data_example/boxes_and_transcripts/')\n",
    "  shutil.copy(out_images+str(row[2])+\".jpg\",'PICK-pytorch/data/test_data_example/images/')\n",
    "  shutil.copy(out_entities +str(row[2])+\".txt\", 'PICK-pytorch/data/test_data_example/entities/')\n",
    "\n",
    "train.drop(['Unnamed: 0'], axis = 1,inplace = True)\n",
    "train.reset_index(inplace= True)\n",
    "train.drop(['index'], axis = 1,inplace = True)\n",
    "train.to_csv(\"PICK-pytorch/data/test_data_example/train_samples_list.csv\",header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1D1cCbr37ow-"
   },
   "outputs": [],
   "source": [
    "## Removing data once it is copied into PICK-pytorch data folder\n",
    "!rm /content/boxes_and_transcripts/*.tsv\n",
    "!rm /content/images/*.jpg\n",
    "!rm /content/entities/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewPOKuFqUiJt",
    "outputId": "07cda905-5e87-45c5-bb36-fb6912b4f155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mula Ram\\NLP\\in\\PICK-pytorch\n"
     ]
    }
   ],
   "source": [
    "%cd PICK-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3_YpmKMWO28",
    "outputId": "252b124e-b672-486d-c110-c0911ba2011b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils/entities_list.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/entities_list.py\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Author: Wenwen Yu\n",
    "# @Created Time: 7/8/2020 9:34 PM\n",
    "\n",
    "Entities_list = [\n",
    "    \"company\",\n",
    "    \"address\",\n",
    "    \"date\",\n",
    "    \"total\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NFD_WzcOWOu2",
    "outputId": "c4cf0a03-6e32-4ed4-bc84-64c31dc4b6b1"
   },
   "outputs": [],
   "source": [
    "## Installing requirements for running PICK-pytorch\n",
    "!pip install -r requirements.txt\n",
    "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOhMZc0Q8MW_"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qu0Nep-Zou31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mula Ram\\NLP\\in\\Scripts\\python.exe: Error while finding module specification for 'torch.distributed.launch' (ModuleNotFoundError: No module named 'torch')\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "!python -m torch.distributed.launch --nnode=1 --node_rank=0 --nproc_per_node=1 \\\n",
    "   train.py -c config.json -d 0 --local_world_size 1\n",
    "  # --resume /content/PICK-pytorch/saved/models/PICK_Default/test_0917_074722/model_best.pth ##uncomment for resume training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Qgs4R9HNWPV"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRfYU-iK5RJu"
   },
   "outputs": [],
   "source": [
    "##creating testing folders\n",
    "!mkdir /content/test_img /content/test_boxes_and_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhMo3SGIE4l6"
   },
   "outputs": [],
   "source": [
    "## copy one file from test sample\n",
    "import os\n",
    "import shutil\n",
    "data_path = \"data/test_data_example/boxes_and_transcripts/\"\n",
    "image_path = \"data/test_data_example/images/\"\n",
    "\n",
    "out_img_path = \"/content/test_img/\"\n",
    "out_box_path = \"/content/test_boxes_and_transcripts/\"\n",
    "\n",
    "for file in os.listdir(data_path)[:10]:\n",
    "  shutil.copy(data_path+file,out_box_path)\n",
    "  shutil.copy(image_path+file.replace(\".tsv\",\".jpg\"),out_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFUSNetJCOM0"
   },
   "outputs": [],
   "source": [
    "## change model_best.pth path\n",
    "!python test.py --checkpoint saved/models/PICK_Default/test_1003_053713/model_best.pth \\\n",
    "                --boxes_transcripts {out_box_path} \\\n",
    "                --images_path {out_img_path} --output_folder /content/output/ \\\n",
    "                --gpu 0 --batch_size 2"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "information_extract_from_invoice_.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
